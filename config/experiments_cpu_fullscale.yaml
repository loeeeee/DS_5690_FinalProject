experiment:
  baseline_id: "meta-llama/Meta-Llama-3-8B"
  target_id: "GSAI-ML/LLaDA-8B-Base"
  precision: "float32"
  max_new_tokens: 128
  warmup: 3
  sequence_lengths: [128, 512, 1024, 2048]
  batch_sizes: [1, 4, 8, 16, 32, 64]
  diffusion_steps: [16, 32, 64, 128, 256]
  notes: "Full scale CPU test configuration - float32 precision for CPU compatibility, comprehensive parameter sweeps across sequence lengths, batch sizes, and diffusion steps."

dataset:
  name: "wikitext"
  config: "wikitext-103-v1"
  split: "validation"
  dataset_size: "large"
  max_prompts: 128

